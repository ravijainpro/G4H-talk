{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "Copy of Text Classification - Walkthrough.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1aJZ0SYTYCLD",
        "colab_type": "text"
      },
      "source": [
        "![No Free Lunch](https://github.com/parth1993/g4h/blob/master/no-free-lunch-theorems-analytics-india-magazine.jpg?raw=1)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_sdN_FyYDzR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iIa1x-ecYCLH",
        "colab_type": "text"
      },
      "source": [
        "# Natural Language Processing for Text Classification with NLTK and Scikit-learn\n",
        "\n",
        "### Presented by Parth Sharma!\n",
        "\n",
        "In this workshop, Text Classification - Walk Through in Python, we will learn about one of the fundamental tasks in Natural Language Processing i.e. **Text Classification**. This will include the basics of feature engineering(tokenizing, stop words, stemming, lemmatizing) and ; furthermore, we will dive into machine learning and text classification using a bunch of differnt techniques and a dataset of positive and negative movie reviews.\n",
        "\n",
        "In this tutorial, we will expand on this foundation and explore different ways to improve our text classification results. We will cover and use:\n",
        "\n",
        "* Regular Expressions\n",
        "* Feature Engineering\n",
        "* Multiple scikit-learn Classifiers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j_b0FIiTYCLH",
        "colab_type": "text"
      },
      "source": [
        "## What is Text Classification?\n",
        "\n",
        "* Refers to process of assigning tags/categories to unstructured text according to it's content \n",
        "* a.k.a Text Categorization or Text Tagging"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KPGNvmq8YCLI",
        "colab_type": "text"
      },
      "source": [
        "## If it's just tagging the text, then why do we need Text Classification?\n",
        "\n",
        "Text classifiers can be used to organize, structure, and categorize pretty much anything. For example, emails can be organized by spam/non-spam, news articles can be organized by topics, support tickets can be organized by urgency, chat conversations can be organized by language, brand mentions can be organized by sentiment, and so on.\n",
        "\n",
        "Tagging raw text would require a lot of resources(workforce and time). Text Classification using NLP resolves these issues and overcome the disadvantages of manual tagging."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q1KQWR9yYCLJ",
        "colab_type": "text"
      },
      "source": [
        "## Types of Text Classification Systems:\n",
        "\n",
        "* Rule Based Systems\n",
        "* **Machine Learning Systems**\n",
        "* Hybrid Systems (Both ML and Rules)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dAnzN5YLYCLK",
        "colab_type": "text"
      },
      "source": [
        "### 1. Import Necessary Libraries\n",
        "To ensure the necessary libraries are installed correctly and up-to-date, print the version numbers for each library. This will also improve the reproducibility of our project."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e4yCHGv8YCLL",
        "colab_type": "code",
        "outputId": "69ad4611-d7f3-4496-dd4d-44345a44b2ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "import sys\n",
        "try:\n",
        "    import nltk\n",
        "except:\n",
        "    !pip install nltk -y\n",
        "    import nltk\n",
        "    nltk.download('all')\n",
        "try:\n",
        "    import sklearn\n",
        "except:\n",
        "    !pip install sklearn -y\n",
        "    import sklearn\n",
        "try:\n",
        "    import pandas as pd\n",
        "except:\n",
        "    !pip install pandas -y\n",
        "    import pandas as pd\n",
        "try:\n",
        "    import numpy as np\n",
        "except:\n",
        "    !pip install numpy -y\n",
        "    import numpy as np\n",
        "try:\n",
        "    import matplotlib.pyplot as plt\n",
        "except:\n",
        "    !pip install matplotlib -y\n",
        "    import matplotlib.pyplot as plt\n",
        "    \n",
        "\n",
        "print('Python: {}'.format(sys.version))\n",
        "print('NLTK: {}'.format(nltk.__version__))\n",
        "print('Scikit-learn: {}'.format(sklearn.__version__))\n",
        "print('Pandas: {}'.format(pd.__version__))\n",
        "print('Numpy: {}'.format(np.__version__))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Python: 3.6.9 (default, Nov  7 2019, 10:44:02) \n",
            "[GCC 8.3.0]\n",
            "NLTK: 3.2.5\n",
            "Scikit-learn: 0.21.3\n",
            "Pandas: 0.25.3\n",
            "Numpy: 1.17.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7W-iQdIPYCLP",
        "colab_type": "text"
      },
      "source": [
        "## 2. Load the Dataset\n",
        "Now that we have ensured that our libraries are installed correctly, let's load the data set as a Pandas DataFrame. Furthermore, let's extract some useful information such as the column information and class distributions.\n",
        "\n",
        "The data set we will be using comes from the Kaggle datasets. It contains over 20001 tweets labeled messages that have been collected for detection of cyber trolls research. It can be downloaded from the following URL:\n",
        "\n",
        "https://www.kaggle.com/dataturks/dataset-for-detection-of-cybertrolls/version/1#"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "jqtw63R0YCLR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_json('Dataset for Detection of Cyber-Trolls.json', lines=True)\n",
        "df = df[['content', 'annotation']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SEjavkMfYCLU",
        "colab_type": "code",
        "outputId": "a542bbff-c20e-4f88-9bd7-721df4bacada",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        }
      },
      "source": [
        "print(df.info())\n",
        "print(df.head())"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 20001 entries, 0 to 20000\n",
            "Data columns (total 2 columns):\n",
            "content       20001 non-null object\n",
            "annotation    20001 non-null object\n",
            "dtypes: object(2)\n",
            "memory usage: 312.6+ KB\n",
            "None\n",
            "                                             content                     annotation\n",
            "0                             Get fucking real dude.  {'notes': '', 'label': ['1']}\n",
            "1   She is as dirty as they come  and that crook ...  {'notes': '', 'label': ['1']}\n",
            "2   why did you fuck it up. I could do it all day...  {'notes': '', 'label': ['1']}\n",
            "3   Dude they dont finish enclosing the fucking s...  {'notes': '', 'label': ['1']}\n",
            "4   WTF are you talking about Men? No men thats n...  {'notes': '', 'label': ['1']}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZWF3hM9YCLW",
        "colab_type": "code",
        "outputId": "c8e6346c-82fb-4c9f-9e6c-c14834c7c716",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#This code will check for any nan values in the dataframe we just loaded\n",
        "df.isnull().values.any()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "69witLz1YCLY",
        "colab_type": "text"
      },
      "source": [
        "#### Class distribution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZeB9-wOYCLY",
        "colab_type": "code",
        "outputId": "4a34e9cd-6f83-4255-844d-65a54b948e5a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "# Class distribution\n",
        "target = df['annotation'].apply(lambda x: int(x['label'][0]))\n",
        "target.value_counts()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    12179\n",
              "1     7822\n",
              "Name: annotation, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58_mFJpdYCLa",
        "colab_type": "code",
        "outputId": "b39b2e47-5f45-4882-ffe9-887fa2bc6a5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "pd.value_counts(target).plot(kind=\"bar\")"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f96bd95aa90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAD1CAYAAACyaJl6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FzFVk_uzYCLd",
        "colab_type": "text"
      },
      "source": [
        "## 3. Preprocess the Data\n",
        "\n",
        "Preprocessing the data is an essential step in natural language process. In the following cells, we will convert our class labels to binary values using the LabelEncoder from sklearn, replace email addresses, URLs, phone numbers, and other symbols by using regular expressions, remove stop words, and extract word stems."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fgEYMGXAYCLd",
        "colab_type": "code",
        "outputId": "f9ad4a5f-8398-4627-8066-dd21572044c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# convert class labels to binary values, 0 = Not a troll and 1 = it's a troll!\n",
        "encoder = LabelEncoder()\n",
        "Y = encoder.fit_transform(target)\n",
        "\n",
        "print(Y[:10])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 1 1 1 1 1 1 1 1 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jamEmLnUYCLi",
        "colab_type": "code",
        "outputId": "bf8cdaef-eb7a-4a18-9a5d-ecaa01306bac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "# store the tweet data\n",
        "tweets = df['content']\n",
        "print(tweets[:10])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0                               Get fucking real dude.\n",
            "1     She is as dirty as they come  and that crook ...\n",
            "2     why did you fuck it up. I could do it all day...\n",
            "3     Dude they dont finish enclosing the fucking s...\n",
            "4     WTF are you talking about Men? No men thats n...\n",
            "5    Ill save you the trouble sister. Here comes a ...\n",
            "6     Im dead serious.Real athletes never cheat don...\n",
            "7    ...go absolutely insane.hate to be the bearer ...\n",
            "8    Lmao  im watching the same thing ahaha. The ga...\n",
            "9    LOL  no he said  What do you call a jail cell ...\n",
            "Name: content, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1nkXq9CYCLl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# use regular expressions to replace email addresses, URLs, phone numbers, other numbers\n",
        "\n",
        "# Replace email addresses with 'email'\n",
        "processed = tweets.str.replace(r'^.+@[^\\.].*\\.[a-z]{2,}$',\n",
        "                                 'emailaddress')\n",
        "\n",
        "# Replace URLs with 'webaddress'\n",
        "processed = processed.str.replace(r'^http\\://[a-zA-Z0-9\\-\\.]+\\.[a-zA-Z]{2,3}(/\\S*)?$',\n",
        "                                  'webaddress')\n",
        "\n",
        "# Replace money symbols with 'moneysymb' (£ can by typed with ALT key + 156)\n",
        "processed = processed.str.replace(r'£|\\$', 'moneysymb')\n",
        "    \n",
        "# Replace 10 digit phone numbers (formats include paranthesis, spaces, no spaces, dashes) with 'phonenumber'\n",
        "processed = processed.str.replace(r'^\\(?[\\d]{3}\\)?[\\s-]?[\\d]{3}[\\s-]?[\\d]{4}$',\n",
        "                                  'phonenumbr')\n",
        "    \n",
        "# Replace numbers with 'numbr'\n",
        "processed = processed.str.replace(r'\\d+(\\.\\d+)?', 'numbr')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lflNqlESYCLm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Remove punctuation\n",
        "processed = processed.str.replace(r'[^\\w\\d\\s]', ' ')\n",
        "\n",
        "# Replace whitespace between terms with a single space\n",
        "processed = processed.str.replace(r'\\s+', ' ')\n",
        "\n",
        "# Remove leading and trailing whitespace\n",
        "processed = processed.str.replace(r'^\\s+|\\s+?$', '')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Z03_HzkYCLo",
        "colab_type": "code",
        "outputId": "266c3854-62d0-432b-da0c-64233900d44c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        }
      },
      "source": [
        "# Change words to lower case\n",
        "processed = processed.str.lower()\n",
        "print(processed)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0                                    get fucking real dude\n",
            "1        she is as dirty as they come and that crook re...\n",
            "2        why did you fuck it up i could do it all day t...\n",
            "3        dude they dont finish enclosing the fucking sh...\n",
            "4        wtf are you talking about men no men thats not...\n",
            "                               ...                        \n",
            "19996    i dont but what is complaining about it going ...\n",
            "19997    bahah yeah i m totally just gonna get pissed a...\n",
            "19998             hahahahaha im evil mwahahahahahahahahaha\n",
            "19999                   what s something unique about ohio\n",
            "20000                 who is the biggest gossiper you know\n",
            "Name: content, Length: 20001, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p4LdF1YPYCLr",
        "colab_type": "code",
        "outputId": "eb449be4-5131-4961-91ed-b4850c49d008",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords #are, is, the --> those words which occurs too frequently and are of no significance.\n",
        "\n",
        "# remove stop words from tweets\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "processed = processed.apply(lambda x: ' '.join(\n",
        "    term for term in x.split() if term not in stop_words))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HkVqH9mkYCLt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Remove word stems using a Porter stemmer  #steam words--> running-->run from run we got running; so run is the steam word for running\n",
        "ps = nltk.PorterStemmer()\n",
        "\n",
        "processed = processed.apply(lambda x: ' '.join(\n",
        "    ps.stem(term) for term in x.split()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TS2zXlvQYCLw",
        "colab_type": "text"
      },
      "source": [
        "## 4. Generating Features\n",
        "Feature engineering is the process of using domain knowledge of the data to create features for machine learning algorithms. In this project, the words in each text message will be our features. For this purpose, it will be necessary to tokenize each word and convert them into vectorized format using TF-IDF."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bCtpjRhVYCLy",
        "colab_type": "code",
        "outputId": "f21ff133-a17a-42a4-f99d-f70a1ba86bc5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "\n",
        "tfidf = TfidfVectorizer(ngram_range=(1,2), min_df=0.01)\n",
        "X = tfidf.fit_transform(processed)\n",
        "\n",
        "print(tfidf.get_feature_names())"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['alway', 'ass', 'back', 'bad', 'better', 'big', 'bitch', 'call', 'com', 'come', 'could', 'damn', 'day', 'dick', 'dont', 'dude', 'even', 'ever', 'fat', 'feel', 'friend', 'fuck', 'gay', 'get', 'girl', 'give', 'go', 'gonna', 'good', 'got', 'guy', 'haha', 'hate', 'hope', 'http', 'im', 'kick', 'kick ass', 'know', 'last', 'let', 'life', 'like', 'lmao', 'lol', 'look', 'love', 'make', 'man', 'mayb', 'mean', 'much', 'name', 'need', 'nerd', 'never', 'new', 'night', 'numbr', 'oh', 'one', 'peopl', 'person', 'pretti', 'realli', 'right', 'say', 'see', 'shit', 'show', 'someon', 'someth', 'sorri', 'still', 'suck', 'sure', 'take', 'talk', 'tell', 'thank', 'that', 'thing', 'think', 'though', 'time', 'tri', 'twitter', 'ur', 'use', 'want', 'watch', 'way', 'well', 'work', 'would', 'ye', 'yeah', 'year']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y9Bna2MJYCL3",
        "colab_type": "code",
        "outputId": "a59150e6-979e-46ee-85b4-36fada6d5f75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(tfidf.get_feature_names())"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "98"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZP-t01JYCL5",
        "colab_type": "code",
        "outputId": "26a49cfc-db7e-421a-bb96-770939c1fc06",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(X.shape)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(20001, 98)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDOgLadUYCL-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# we can split the featuresets into training and testing datasets using sklearn\n",
        "from sklearn import model_selection\n",
        "\n",
        "# split the data into training and testing datasets\n",
        "training, testing, y_train, y_test = model_selection.train_test_split(X, Y, stratify=Y, test_size = 0.25, random_state=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dNHZVYWgYCL_",
        "colab_type": "text"
      },
      "source": [
        "## 5. Model Development"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qA-8ALyjYCMF",
        "colab_type": "code",
        "outputId": "bf9762c6-5ebd-4460-dda6-9564c4784fb0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        }
      },
      "source": [
        "from sklearn.ensemble import VotingClassifier, RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
        "\n",
        "# Define models to train\n",
        "names = [\"Logistic Regression\", \"SGD Classifier\",\n",
        "         \"Naive Bayes\", \"SVM Linear\"]\n",
        "\n",
        "classifiers = [\n",
        "    LogisticRegression(),\n",
        "    SGDClassifier(max_iter = 100),\n",
        "    MultinomialNB(),\n",
        "    SVC(kernel = 'linear')\n",
        "]\n",
        "clf1 = LogisticRegression()\n",
        "clf2 = RandomForestClassifier()\n",
        "clf3 = MultinomialNB()\n",
        "clf4 = SVC(kernel = 'linear')\n",
        "models = zip(names, classifiers)\n",
        "\n",
        "for name, model in models:\n",
        "    nlp_model = model\n",
        "    nlp_model.fit(training, y_train)\n",
        "    accuracy = nlp_model.score(testing, y_test)*100\n",
        "    print(\"{} Accuracy: {}\".format(name, accuracy))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Logistic Regression Accuracy: 68.68626274745051\n",
            "SGD Classifier Accuracy: 68.0863827234553\n",
            "Naive Bayes Accuracy: 66.62667466506699\n",
            "SVM Linear Accuracy: 67.92641471705659\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wt3SJ8eFYCMJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Ensemble model using different classifiers\n",
        "\n",
        "ensemble_model = VotingClassifier(estimators=[('lr', clf1), ('rf', clf2), ('nb', clf3),\n",
        "                                              ('svm', clf4)], voting ='hard')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "sCXAQLmwYCML",
        "colab_type": "code",
        "outputId": "fab21d1c-e023-4951-8846-518ff5fe7bec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "ensemble_model.fit(training, y_train)\n",
        "accuracy = ensemble_model.score(testing, y_test)*100\n",
        "print(\"{} Accuracy: {}\".format('Ensemble model', accuracy))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Ensemble model Accuracy: 69.70605878824236\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TH7rN6tYYCMN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prediction = ensemble_model.predict(testing)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VvyOKSUyYCMO",
        "colab_type": "code",
        "outputId": "c853c3ab-bc59-4abf-8665-6fb4a510438d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        }
      },
      "source": [
        "print(classification_report(y_test, prediction))\n",
        "\n",
        "pd.DataFrame(\n",
        "    confusion_matrix(y_test, prediction),\n",
        "    index = [['actual', 'actual'], ['Troll', 'Non-Troll']],\n",
        "    columns = [['predicted', 'predicted'], ['Troll', 'Non-Troll']])"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.70      0.88      0.78      3045\n",
            "           1       0.69      0.41      0.51      1956\n",
            "\n",
            "    accuracy                           0.70      5001\n",
            "   macro avg       0.69      0.65      0.65      5001\n",
            "weighted avg       0.70      0.70      0.68      5001\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th colspan=\"2\" halign=\"left\">predicted</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>Troll</th>\n",
              "      <th>Non-Troll</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">actual</th>\n",
              "      <th>Troll</th>\n",
              "      <td>2682</td>\n",
              "      <td>363</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Non-Troll</th>\n",
              "      <td>1152</td>\n",
              "      <td>804</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 predicted          \n",
              "                     Troll Non-Troll\n",
              "actual Troll          2682       363\n",
              "       Non-Troll      1152       804"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ONjvNpEhYCMQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}